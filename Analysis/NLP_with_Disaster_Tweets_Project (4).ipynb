{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ENrZEt4Aq9Nx"
      },
      "outputs": [],
      "source": [
        "# Importing the Libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I26VMsY2aIFf",
        "outputId": "6b3d74d0-001d-44eb-bf36-5a973eb7a826"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "Xs5kslhjaIzY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Dataset\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "i_uK0-EBaK1M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking observation and feature numbers for train and test data.\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLqkjONqaXJQ",
        "outputId": "ab5feac3-8ada-44f8-8f62-448f29137074"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7613, 5)\n",
            "(7613, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking general look at the training datasets.\n",
        "print(train_data.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX0AknAtaYfa",
        "outputId": "097f248c-a4a1-41a6-f215-6ed1cc8e2260"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id keyword location                                               text  \\\n",
            "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
            "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
            "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
            "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
            "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
            "\n",
            "   target  \n",
            "0       1  \n",
            "1       1  \n",
            "2       1  \n",
            "3       1  \n",
            "4       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking general look at the testing datasets.\n",
        "print(test_data.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5PZ33C6ab6A",
        "outputId": "dc61edf1-6528-4a91-9764-94bedb13c482"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id keyword location                                               text  \\\n",
            "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
            "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
            "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
            "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
            "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
            "\n",
            "   target  \n",
            "0       1  \n",
            "1       1  \n",
            "2       1  \n",
            "3       1  \n",
            "4       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Check for NaN and convert to empty string if necessary\n",
        "    if isinstance(text, float) and np.isnan(text):\n",
        "        text = ''\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    # Remove user mentions\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stop words\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatization\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "3HWgdBHRaeGu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing\n",
        "train_data['cleaned_text'] = train_data['text'].apply(preprocess_text)\n",
        "test_data['cleaned_text'] = test_data['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "hQj_228raoCk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the original text column\n",
        "train_data.drop(columns=['text'], inplace=True)\n",
        "test_data.drop(columns=['text'], inplace=True)"
      ],
      "metadata": {
        "id": "GIABJiU9apyX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values\n",
        "train_data['cleaned_text'].fillna('', inplace=True)\n",
        "test_data['cleaned_text'].fillna('', inplace=True)"
      ],
      "metadata": {
        "id": "2fsbzcKebev4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the cleaned data\n",
        "train_data.to_csv('cleaned_disaster_tweets.csv', index=False)\n",
        "test_data.to_csv('cleaned_test_tweets.csv', index=False)"
      ],
      "metadata": {
        "id": "0DS8OEv8arXj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the preprocessed data\n",
        "tweets_data = pd.read_csv('cleaned_disaster_tweets.csv')\n",
        "test_data = pd.read_csv('cleaned_test_tweets.csv')"
      ],
      "metadata": {
        "id": "TUa5hX1natmt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure there are no NaN values\n",
        "tweets_data['cleaned_text'].fillna('', inplace=True)"
      ],
      "metadata": {
        "id": "PV-dMDXsa9fN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into features and target\n",
        "X = train_data['cleaned_text']\n",
        "y = train_data['target']"
      ],
      "metadata": {
        "id": "-WbPa1jqavXq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_test = test_data['cleaned_text']"
      ],
      "metadata": {
        "id": "vAlcW6z6axEm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure there are no NaN values in the split data\n",
        "X_train.fillna('', inplace=True)\n",
        "X_val.fillna('', inplace=True)\n",
        "X_test.fillna('', inplace=True)"
      ],
      "metadata": {
        "id": "rA6FaVQWdMQ_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "xxJVAavaay4N"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec Vectorization\n",
        "X_train_tokens = [text.split() for text in X_train]\n",
        "X_val_tokens = [text.split() for text in X_val]\n",
        "X_test_tokens = [text.split() for text in X_test]\n",
        "w2v_model = Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
        "w2v_model.train(X_train_tokens, total_examples=len(X_train_tokens), epochs=10)\n",
        "\n",
        "def average_word_vectors(words, model, vocabulary, num_features):\n",
        "    feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
        "    n_words = 0.\n",
        "    for word in words:\n",
        "        if word in vocabulary:\n",
        "            n_words += 1.\n",
        "            feature_vector = np.add(feature_vector, model.wv[word])\n",
        "    if n_words:\n",
        "        feature_vector = np.divide(feature_vector, n_words)\n",
        "    return feature_vector\n",
        "\n",
        "def averaged_word_vectorizer(texts, model, num_features):\n",
        "    vocabulary = set(model.wv.key_to_index)\n",
        "    features = [average_word_vectors(text, model, vocabulary, num_features) for text in texts]\n",
        "    return np.array(features)\n",
        "\n",
        "X_train_w2v = averaged_word_vectorizer(X_train_tokens, w2v_model, 100)\n",
        "X_val_w2v = averaged_word_vectorizer(X_val_tokens, w2v_model, 100)\n",
        "X_test_w2v = averaged_word_vectorizer(X_test_tokens, w2v_model, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rPKj6_Ca0pN",
        "outputId": "02ebc81e-ac8a-4ab8-c58b-c397ebda4daf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine TF-IDF and Word2Vec Features\n",
        "X_train_combined = np.hstack((X_train_tfidf.toarray(), X_train_w2v))\n",
        "X_val_combined = np.hstack((X_val_tfidf.toarray(), X_val_w2v))\n",
        "X_test_combined = np.hstack((X_test_tfidf.toarray(), X_test_w2v))"
      ],
      "metadata": {
        "id": "3Jk5GcazdXsA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build and evaluate models\n",
        "def build_and_evaluate_model(ModelClass, X_train, X_val, y_train, y_val):\n",
        "    model = ModelClass()\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    report = classification_report(y_val, y_pred)\n",
        "    return model, accuracy, report"
      ],
      "metadata": {
        "id": "ZBNd2PwGdaFE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Models to evaluate\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier,\n",
        "    'SVM': SVC,\n",
        "    'Logistic Regression': LogisticRegression\n",
        "}"
      ],
      "metadata": {
        "id": "Bgk_D_esdce2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models on TF-IDF features\n",
        "results_tfidf = {}\n",
        "for name, ModelClass in models.items():\n",
        "    print(f\"Evaluating {name} with TF-IDF features...\")\n",
        "    model, accuracy, report = build_and_evaluate_model(ModelClass, X_train_tfidf, X_val_tfidf, y_train, y_val)\n",
        "    results_tfidf[name] = (model, accuracy, report)\n",
        "    print(f\"{name} Accuracy (TF-IDF): {accuracy}\\n\")\n",
        "    print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOO_e0cBdef5",
        "outputId": "ce067a2a-6335-4d4d-956c-f64e37ca73a8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Random Forest with TF-IDF features...\n",
            "Random Forest Accuracy (TF-IDF): 0.7596848325673013\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.82      0.80       874\n",
            "           1       0.73      0.68      0.71       649\n",
            "\n",
            "    accuracy                           0.76      1523\n",
            "   macro avg       0.76      0.75      0.75      1523\n",
            "weighted avg       0.76      0.76      0.76      1523\n",
            "\n",
            "Evaluating SVM with TF-IDF features...\n",
            "SVM Accuracy (TF-IDF): 0.7997373604727511\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84       874\n",
            "           1       0.82      0.68      0.74       649\n",
            "\n",
            "    accuracy                           0.80      1523\n",
            "   macro avg       0.80      0.78      0.79      1523\n",
            "weighted avg       0.80      0.80      0.80      1523\n",
            "\n",
            "Evaluating Logistic Regression with TF-IDF features...\n",
            "Logistic Regression Accuracy (TF-IDF): 0.8017071569271176\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84       874\n",
            "           1       0.82      0.69      0.75       649\n",
            "\n",
            "    accuracy                           0.80      1523\n",
            "   macro avg       0.81      0.79      0.79      1523\n",
            "weighted avg       0.80      0.80      0.80      1523\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models on Word2Vec features\n",
        "results_w2v = {}\n",
        "for name, ModelClass in models.items():\n",
        "    print(f\"Evaluating {name} with Word2Vec features...\")\n",
        "    model, accuracy, report = build_and_evaluate_model(ModelClass, X_train_w2v, X_val_w2v, y_train, y_val)\n",
        "    results_w2v[name] = (model, accuracy, report)\n",
        "    print(f\"{name} Accuracy (Word2Vec): {accuracy}\\n\")\n",
        "    print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-vZ6vendgh2",
        "outputId": "728d0ecf-0913-4b1f-b121-71f3bf02d074"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Random Forest with Word2Vec features...\n",
            "Random Forest Accuracy (Word2Vec): 0.737360472751149\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.82      0.78       874\n",
            "           1       0.72      0.62      0.67       649\n",
            "\n",
            "    accuracy                           0.74      1523\n",
            "   macro avg       0.73      0.72      0.73      1523\n",
            "weighted avg       0.74      0.74      0.73      1523\n",
            "\n",
            "Evaluating SVM with Word2Vec features...\n",
            "SVM Accuracy (Word2Vec): 0.7071569271175312\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.92      0.78       874\n",
            "           1       0.79      0.42      0.55       649\n",
            "\n",
            "    accuracy                           0.71      1523\n",
            "   macro avg       0.74      0.67      0.67      1523\n",
            "weighted avg       0.73      0.71      0.68      1523\n",
            "\n",
            "Evaluating Logistic Regression with Word2Vec features...\n",
            "Logistic Regression Accuracy (Word2Vec): 0.7176625082074852\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.87      0.78       874\n",
            "           1       0.74      0.52      0.61       649\n",
            "\n",
            "    accuracy                           0.72      1523\n",
            "   macro avg       0.72      0.69      0.69      1523\n",
            "weighted avg       0.72      0.72      0.71      1523\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models on Combined features\n",
        "results_combined = {}\n",
        "for name, ModelClass in models.items():\n",
        "    print(f\"Evaluating {name} with Combined TF-IDF and Word2Vec features...\")\n",
        "    model, accuracy, report = build_and_evaluate_model(ModelClass, X_train_combined, X_val_combined, y_train, y_val)\n",
        "    results_combined[name] = (model, accuracy, report)\n",
        "    print(f\"{name} Accuracy (Combined): {accuracy}\\n\")\n",
        "    print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMP2SRYYdllb",
        "outputId": "6f4b3f8f-0fcc-4374-95a3-42fda65b9e84"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Random Forest with Combined TF-IDF and Word2Vec features...\n",
            "Random Forest Accuracy (Combined): 0.7413000656598818\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.84      0.79       874\n",
            "           1       0.74      0.61      0.67       649\n",
            "\n",
            "    accuracy                           0.74      1523\n",
            "   macro avg       0.74      0.72      0.73      1523\n",
            "weighted avg       0.74      0.74      0.74      1523\n",
            "\n",
            "Evaluating SVM with Combined TF-IDF and Word2Vec features...\n",
            "SVM Accuracy (Combined): 0.7820091923834537\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.91      0.83       874\n",
            "           1       0.83      0.61      0.71       649\n",
            "\n",
            "    accuracy                           0.78      1523\n",
            "   macro avg       0.79      0.76      0.77      1523\n",
            "weighted avg       0.79      0.78      0.78      1523\n",
            "\n",
            "Evaluating Logistic Regression with Combined TF-IDF and Word2Vec features...\n",
            "Logistic Regression Accuracy (Combined): 0.7951411687458962\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.87      0.83       874\n",
            "           1       0.80      0.70      0.74       649\n",
            "\n",
            "    accuracy                           0.80      1523\n",
            "   macro avg       0.80      0.78      0.79      1523\n",
            "weighted avg       0.80      0.80      0.79      1523\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning for the best model\n",
        "# Let's assume Logistic Regression with Combined features performed the best\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'solver': ['liblinear', 'lbfgs']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_combined, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "y_pred_best = best_model.predict(X_val_combined)\n",
        "best_accuracy = accuracy_score(y_val, y_pred_best)\n",
        "best_report = classification_report(y_val, y_pred_best)\n",
        "\n",
        "print(\"Best Model Accuracy after Hyperparameter Tuning:\", best_accuracy)\n",
        "print(\"Best Model Classification Report after Hyperparameter Tuning:\\n\", best_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA0BWjj64hHP",
        "outputId": "e67b0594-9837-4db7-917e-890a30fa1b53"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 1, 'solver': 'liblinear'}\n",
            "Best Model Accuracy after Hyperparameter Tuning: 0.7964543663821405\n",
            "Best Model Classification Report after Hyperparameter Tuning:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.87      0.83       874\n",
            "           1       0.80      0.70      0.75       649\n",
            "\n",
            "    accuracy                           0.80      1523\n",
            "   macro avg       0.80      0.78      0.79      1523\n",
            "weighted avg       0.80      0.80      0.79      1523\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model and TF-IDF vectorizer\n",
        "import joblib\n",
        "joblib.dump(best_model, 'logistic_model.pkl')\n",
        "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')\n",
        "joblib.dump(w2v_model, 'word2vec.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5YoDnJ34-x0",
        "outputId": "df163b2f-96ef-4ec7-be71-5410154b4c82"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['word2vec.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}